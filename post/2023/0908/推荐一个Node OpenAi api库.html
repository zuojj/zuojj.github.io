
<!DOCTYPE html>
<html lang="zh-cn">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="煦涵驛">
    <title>2023/0908/推荐一个Node OpenAi api库 - 煦涵驛</title>
    <meta name="author" content="煦涵">
    
        <meta name="keywords" content="WEB开发,前端开发,用户体验">
    
    
        <link rel="icon" href="https://zuojj.com/assets/images/favicon.ico">
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"煦涵","sameAs":["https://github.com/zuojj","mailto:zuojj.com@gmail.com"],"image":"android-icon-192x192.png"},"articleBody":"当谈到使用OpenAI API库时，有几个选择可以考虑。以下是我推荐的一个：\nnode-openai\nnode-openai是一个Node.js库，它提供了一个简单的方法来调用OpenAI GPT API。它使用HTTP请求与OpenAI API进行交互，并返回JSON格式的响应。这使得与OpenAI GPT API的交互变得更加容易和简单。\n以下是一个使用node-openai的基本示例：\n1234567891011const OpenAI = require('node-openai');const GPT = new OpenAI('YOUR_API_KEY');GPT.text('hello world', (err, response) =&gt; &#123;  if (err) &#123;    console.error(err);  &#125; else &#123;    console.log(response);  &#125;&#125;);\n在上面的示例中，我们使用node-openai创建了一个新的API实例，并调用了text方法，传入了一个文本查询和一个回调函数。回调函数会在API响应时被执行，并可以处理响应数据。\n与其他库相比，node-openai非常年轻，因此它可能不是最成熟或最稳定的选择。但是，如果您正在寻找一个简单并且易于使用的Node.js库来调用OpenAI GPT API，那么node-openai是一个不错的选择。\n下面是一个demo代码：\n1234567891011const OpenAI = require('node-openai');const GPT = new OpenAI('YOUR_API_KEY');GPT.text('hello world', (err, response) =&gt; &#123;  if (err) &#123;    console.error(err);  &#125; else &#123;    console.log(response);  &#125;&#125;);\n在上面的代码中，我们使用node-openai创建了一个新的API实例，并调用了text方法，传入了一个文本查询和一个回调函数。回调函数会在API响应时被执行，并可以处理响应数据。\n与其他库相比，node-openai非常年轻，因此它可能不是最成熟或最稳定的选择。但是，如果您正在寻找一个简单并且易于使用的Node.js库来调用OpenAI GPT API，那么node-openai是一个不错的选择。\nOpenAI Node API Library\nThis library provides convenient access to the OpenAI REST API from TypeScript or JavaScript.\nIt is generated from our OpenAPI specification with Stainless.\nTo learn how to use the OpenAI API, check out our API Reference and Documentation.\nInstallation123npm install --save openai# oryarn add openai\n\nUsageThe full API of this library can be found in api.md file. The code below shows how to get started using the chat completions API.\n12345678910111213141516import OpenAI from 'openai';const openai = new OpenAI(&#123;  apiKey: 'my api key', // defaults to process.env[\"OPENAI_API_KEY\"]&#125;);async function main() &#123;  const completion = await openai.chat.completions.create(&#123;    messages: [&#123; role: 'user', content: 'Say this is a test' &#125;],    model: 'gpt-3.5-turbo',  &#125;);  console.log(completion.choices);&#125;main();\n\nStreaming ResponsesWe provide support for streaming responses using Server Sent Events (SSE).\n12345678910111213141516import OpenAI from 'openai';const openai = new OpenAI();async function main() &#123;  const stream = await openai.chat.completions.create(&#123;    model: 'gpt-4',    messages: [&#123; role: 'user', content: 'Say this is a test' &#125;],    stream: true,  &#125;);  for await (const part of stream) &#123;    process.stdout.write(part.choices[0]?.delta?.content || '');  &#125;&#125;main();\n\nIf you need to cancel a stream, you can break from the loopor call stream.controller.abort().\nRequest &amp; Response typesThis library includes TypeScript definitions for all request params and response fields. You may import and use them like so:\n123456789101112131415import OpenAI from 'openai';const openai = new OpenAI(&#123;  apiKey: 'my api key', // defaults to process.env[\"OPENAI_API_KEY\"]&#125;);async function main() &#123;  const params: OpenAI.Chat.ChatCompletionCreateParams = &#123;    messages: [&#123; role: 'user', content: 'Say this is a test' &#125;],    model: 'gpt-3.5-turbo',  &#125;;  const completion: OpenAI.Chat.ChatCompletion = await openai.chat.completions.create(params);&#125;main();\n\nDocumentation for each method, request param, and response field are available in docstrings and will appear on hover in most modern editors.\n\n[!IMPORTANT]Previous versions of this SDK used a Configuration class. See the v3 to v4 migration guide.\n\nFile UploadsRequest parameters that correspond to file uploads can be passed in many different forms:\n\nFile (or an object with the same structure)\na fetch Response (or an object with the same structure)\nan fs.ReadStream\nthe return value of our toFile helper\n\n123456789101112131415161718192021222324import fs from 'fs';import fetch from 'node-fetch';import OpenAI, &#123; toFile &#125; from 'openai';const openai = new OpenAI();// If you have access to Node `fs` we recommend using `fs.createReadStream()`:await openai.files.create(&#123; file: fs.createReadStream('input.jsonl'), purpose: 'fine-tune' &#125;);// Or if you have the web `File` API you can pass a `File` instance:await openai.files.create(&#123; file: new File(['my bytes'], 'input.jsonl'), purpose: 'fine-tune' &#125;);// You can also pass a `fetch` `Response`:await openai.files.create(&#123; file: await fetch('https://somesite/input.jsonl'), purpose: 'fine-tune' &#125;);// Finally, if none of the above are convenient, you can use our `toFile` helper:await openai.files.create(&#123;  file: await toFile(Buffer.from('my bytes'), 'input.jsonl'),  purpose: 'fine-tune',&#125;);await openai.files.create(&#123;  file: await toFile(new Uint8Array([0, 1, 2]), 'input.jsonl'),  purpose: 'fine-tune',&#125;);\n\nHandling errorsWhen the library is unable to connect to the API,or if the API returns a non-success status code (i.e., 4xx or 5xx response),a subclass of APIError will be thrown:\n12345678910111213141516async function main() &#123;  const fineTune = await openai.fineTunes    .create(&#123; training_file: 'file-XGinujblHPwGLSztz8cPS8XY' &#125;)    .catch((err) =&gt; &#123;      if (err instanceof OpenAI.APIError) &#123;        console.log(err.status); // 400        console.log(err.name); // BadRequestError        console.log(err.headers); // &#123;server: 'nginx', ...&#125;      &#125; else &#123;        throw err;      &#125;    &#125;);&#125;main();\n\nError codes are as followed:\n\n\n\nStatus Code\nError Type\n\n\n\n400\nBadRequestError\n\n\n401\nAuthenticationError\n\n\n403\nPermissionDeniedError\n\n\n404\nNotFoundError\n\n\n422\nUnprocessableEntityError\n\n\n429\nRateLimitError\n\n\n&gt;=500\nInternalServerError\n\n\nN/A\nAPIConnectionError\n\n\nAzure OpenAIAn example of using this library with Azure OpenAI can be found here.\nPlease note there are subtle differences in API shape &amp; behavior between the Azure OpenAI API and the OpenAI API,so using this library with Azure OpenAI may result in incorrect types, which can lead to bugs.\nSee @azure/openai for an Azure-specific SDK provided by Microsoft.\nRetriesCertain errors will be automatically retried 2 times by default, with a short exponential backoff.Connection errors (for example, due to a network connectivity problem), 409 Conflict, 429 Rate Limit,and &gt;=500 Internal errors will all be retried by default.\nYou can use the maxRetries option to configure or disable this:\n\n123456789// Configure the default for all requests:const openai = new OpenAI(&#123;  maxRetries: 0, // default is 2&#125;);// Or, configure per-request:await openai.chat.completions.create(&#123; messages: [&#123; role: 'user', content: 'How can I get the name of the current day in Node.js?' &#125;], model: 'gpt-3.5-turbo' &#125;, &#123;  maxRetries: 5,&#125;);\n\nTimeoutsRequests time out after 10 minutes by default. You can configure this with a timeout option:\n\n123456789// Configure the default for all requests:const openai = new OpenAI(&#123;  timeout: 20 * 1000, // 20 seconds (default is 10 minutes)&#125;);// Override per-request:await openai.chat.completions.create(&#123; messages: [&#123; role: 'user', content: 'How can I list all files in a directory using Python?' &#125;], model: 'gpt-3.5-turbo' &#125;, &#123;  timeout: 5 * 1000,&#125;);\n\nOn timeout, an APIConnectionTimeoutError is thrown.\nNote that requests which time out will be retried twice by default.\nAuto-paginationList methods in the OpenAI API are paginated.You can use for await … of syntax to iterate through items across all pages:\n12345678async function fetchAllFineTuningJobs(params) &#123;  const allFineTuningJobs = [];  // Automatically fetches more pages as needed.  for await (const job of openai.fineTuning.jobs.list(&#123; limit: 20 &#125;)) &#123;    allFineTuningJobs.push(job);  &#125;  return allFineTuningJobs;&#125;\n\nAlternatively, you can make request a single page at a time:\n12345678910let page = await openai.fineTuning.jobs.list(&#123; limit: 20 &#125;);for (const job of page.data) &#123;  console.log(job);&#125;// Convenience methods are provided for manually paginating:while (page.hasNextPage()) &#123;  page = page.getNextPage();  // ...&#125;\n\nAdvanced UsageAccessing raw Response data (e.g., headers)The “raw” Response returned by fetch() can be accessed through the .asResponse() method on the APIPromise type that all methods return.\nYou can also use the .withResponse() method to get the raw Response along with the parsed data.\n12345678910111213const openai = new OpenAI();const response = await openai.chat.completions  .create(&#123; messages: [&#123; role: 'user', content: 'Say this is a test' &#125;], model: 'gpt-3.5-turbo' &#125;)  .asResponse();console.log(response.headers.get('X-My-Header'));console.log(response.statusText); // access the underlying Response objectconst &#123; data: completions, response: raw &#125; = await openai.chat.completions  .create(&#123; messages: [&#123; role: 'user', content: 'Say this is a test' &#125;], model: 'gpt-3.5-turbo' &#125;)  .withResponse();console.log(raw.headers.get('X-My-Header'));console.log(completions.choices);\n\nConfiguring an HTTP(S) Agent (e.g., for proxies)By default, this library uses a stable agent for all http/https requests to reuse TCP connections, eliminating many TCP &amp; TLS handshakes and shaving around 100ms off most requests.\nIf you would like to disable or customize this behavior, for example to use the API behind a proxy, you can pass an httpAgent which is used for all requests (be they http or https), for example:\n\n12345678910111213import http from 'http';import HttpsProxyAgent from 'https-proxy-agent';// Configure the default for all requests:const openai = new OpenAI(&#123;  httpAgent: new HttpsProxyAgent(process.env.PROXY_URL),&#125;);// Override per-request:await openai.models.list(&#123;  baseURL: 'http://localhost:8080/test-api',  httpAgent: new http.Agent(&#123; keepAlive: false &#125;),&#125;)\n\nSemantic VersioningThis package generally attempts to follow SemVer conventions, though certain backwards-incompatible changes may be released as minor versions:\n\nChanges that only affect static types, without breaking runtime behavior.\nChanges to library internals which are technically public but not intended or documented for external use. (Please open a GitHub issue to let us know if you are relying on such internals).\nChanges that we do not expect to impact the vast majority of users in practice.\n\nWe take backwards-compatibility seriously and work hard to ensure you can rely on a smooth upgrade experience.\nWe are keen for your feedback; please open an issue with questions, bugs, or suggestions.\nRequirementsTypeScript &gt;= 4.5 is supported.\nThe following runtimes are supported:\n\nNode.js 16 LTS or later (non-EOL) versions.\nDeno v1.28.0 or higher, using import OpenAI from &quot;npm:openai&quot;.Deno Deploy is not yet supported.\nCloudflare Workers.\nVercel Edge Runtime.\n\nIf you are interested in other runtime environments, please open or upvote an issue on GitHub.\n","dateCreated":"2023-09-07T23:13:18+08:00","dateModified":"2023-09-07T23:13:18+08:00","datePublished":"2023-09-07T23:13:18+08:00","description":"","headline":"2023/0908/推荐一个Node OpenAi api库","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html"},"publisher":{"@type":"Organization","name":"煦涵","sameAs":["https://github.com/zuojj","mailto:zuojj.com@gmail.com"],"image":"android-icon-192x192.png","logo":{"@type":"ImageObject","url":"android-icon-192x192.png"}},"url":"https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html"}</script>
    <meta name="description" content="当谈到使用OpenAI API库时，有几个选择可以考虑。以下是我推荐的一个： node-openai node-openai是一个Node.js库，它提供了一个简单的方法来调用OpenAI GPT API。它使用HTTP请求与OpenAI API进行交互，并返回JSON格式的响应。这使得与OpenAI GPT API的交互变得更加容易和简单。 以下是一个使用node-openai的基本示例： 12">
<meta property="og:type" content="blog">
<meta property="og:title" content="2023&#x2F;0908&#x2F;推荐一个Node OpenAi api库">
<meta property="og:url" content="https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html">
<meta property="og:site_name" content="煦涵驛">
<meta property="og:description" content="当谈到使用OpenAI API库时，有几个选择可以考虑。以下是我推荐的一个： node-openai node-openai是一个Node.js库，它提供了一个简单的方法来调用OpenAI GPT API。它使用HTTP请求与OpenAI API进行交互，并返回JSON格式的响应。这使得与OpenAI GPT API的交互变得更加容易和简单。 以下是一个使用node-openai的基本示例： 12">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img.shields.io/npm/v/openai.svg">
<meta property="article:published_time" content="2023-09-07T15:13:18.633Z">
<meta property="article:modified_time" content="2023-09-07T15:13:18.633Z">
<meta property="article:author" content="煦涵">
<meta property="article:tag" content="WEB开发">
<meta property="article:tag" content="前端开发">
<meta property="article:tag" content="用户体验">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img.shields.io/npm/v/openai.svg">
<meta name="twitter:creator" content="@https:&#x2F;&#x2F;twitter.com&#x2F;zuojj">
    
    
        
    
    
        <meta property="og:image" content="https://zuojj.com/assets/images/android-icon-192x192.png"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-athhlbkl2h9o0tjyweq8ul0h4utvjcbpwygudrdazywyt94bvtc6uxmypt2m.min.css">

    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-159301267-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-159301267-1');
    </script>


    

    
        
            
<link rel="stylesheet" href="/assets/css/gitalk.css">

        
    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="5">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/%20"
            aria-label=""
        >
            煦涵驛
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="打开链接: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/android-icon-192x192.png" alt="作者的图片"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="5">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="阅读有关作者的更多信息"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/android-icon-192x192.png" alt="作者的图片" onerror="this.style.display='none'"/>
                </a>
                <h4 class="sidebar-profile-name">煦涵</h4>
                
                    <h5 class="sidebar-profile-bio"><p>因为热爱，所以坚持。</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="分类"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">分类</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="归档"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">归档</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/zuojj"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:zuojj.com@gmail.com"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="邮箱"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">邮箱</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="5"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            2023/0908/推荐一个Node OpenAi api库
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2023-09-07T23:13:18+08:00">
	
		    9月 07, 2023
    	
    </time>
    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>当谈到使用OpenAI API库时，有几个选择可以考虑。以下是我推荐的一个：</p>
<p><strong>node-openai</strong></p>
<p>node-openai是一个Node.js库，它提供了一个简单的方法来调用OpenAI GPT API。它使用HTTP请求与OpenAI API进行交互，并返回JSON格式的响应。这使得与OpenAI GPT API的交互变得更加容易和简单。</p>
<p>以下是一个使用node-openai的基本示例：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> OpenAI = <span class="built_in">require</span>(<span class="string">'node-openai'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> GPT = <span class="keyword">new</span> OpenAI(<span class="string">'YOUR_API_KEY'</span>);</span><br><span class="line"></span><br><span class="line">GPT.text(<span class="string">'hello world'</span>, (err, response) =&gt; &#123;</span><br><span class="line">  <span class="keyword">if</span> (err) &#123;</span><br><span class="line">    <span class="built_in">console</span>.error(err);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(response);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>在上面的示例中，我们使用node-openai创建了一个新的API实例，并调用了<code>text</code>方法，传入了一个文本查询和一个回调函数。回调函数会在API响应时被执行，并可以处理响应数据。</p>
<p>与其他库相比，node-openai非常年轻，因此它可能不是最成熟或最稳定的选择。但是，如果您正在寻找一个简单并且易于使用的Node.js库来调用OpenAI GPT API，那么node-openai是一个不错的选择。</p>
<p>下面是一个demo代码：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> OpenAI = <span class="built_in">require</span>(<span class="string">'node-openai'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> GPT = <span class="keyword">new</span> OpenAI(<span class="string">'YOUR_API_KEY'</span>);</span><br><span class="line"></span><br><span class="line">GPT.text(<span class="string">'hello world'</span>, (err, response) =&gt; &#123;</span><br><span class="line">  <span class="keyword">if</span> (err) &#123;</span><br><span class="line">    <span class="built_in">console</span>.error(err);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(response);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>在上面的代码中，我们使用node-openai创建了一个新的API实例，并调用了<code>text</code>方法，传入了一个文本查询和一个回调函数。回调函数会在API响应时被执行，并可以处理响应数据。</p>
<p>与其他库相比，node-openai非常年轻，因此它可能不是最成熟或最稳定的选择。但是，如果您正在寻找一个简单并且易于使用的Node.js库来调用OpenAI GPT API，那么node-openai是一个不错的选择。</p>
<h1 id="OpenAI-Node-API-Library"><a href="#OpenAI-Node-API-Library" class="headerlink" title="OpenAI Node API Library"></a>OpenAI Node API Library</h1><p><a href="https://npmjs.org/package/openai" target="_blank" rel="noopener"><img src="https://img.shields.io/npm/v/openai.svg" alt="NPM version"></a></p>
<p>This library provides convenient access to the OpenAI REST API from TypeScript or JavaScript.</p>
<p>It is generated from our <a href="https://github.com/openai/openai-openapi" target="_blank" rel="noopener">OpenAPI specification</a> with <a href="https://stainlessapi.com/" target="_blank" rel="noopener">Stainless</a>.</p>
<p>To learn how to use the OpenAI API, check out our <a href="https://platform.openai.com/docs/api-reference" target="_blank" rel="noopener">API Reference</a> and <a href="https://platform.openai.com/docs" target="_blank" rel="noopener">Documentation</a>.</p>
<h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install --save openai</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">yarn add openai</span><br></pre></td></tr></table></figure>

<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>The full API of this library can be found in <a href="https://github.com/openai/openai-node/blob/master/api.md" target="_blank" rel="noopener">api.md file</a>. The code below shows how to get started using the chat completions API.</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> OpenAI <span class="keyword">from</span> <span class="string">'openai'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> openai = <span class="keyword">new</span> OpenAI(&#123;</span><br><span class="line">  apiKey: <span class="string">'my api key'</span>, <span class="comment">// defaults to process.env["OPENAI_API_KEY"]</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">main</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> completion = <span class="keyword">await</span> openai.chat.completions.create(&#123;</span><br><span class="line">    messages: [&#123; <span class="attr">role</span>: <span class="string">'user'</span>, <span class="attr">content</span>: <span class="string">'Say this is a test'</span> &#125;],</span><br><span class="line">    model: <span class="string">'gpt-3.5-turbo'</span>,</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">console</span>.log(completion.choices);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main();</span><br></pre></td></tr></table></figure>

<h2 id="Streaming-Responses"><a href="#Streaming-Responses" class="headerlink" title="Streaming Responses"></a>Streaming Responses</h2><p>We provide support for streaming responses using Server Sent Events (SSE).</p>
<figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> OpenAI <span class="keyword">from</span> <span class="string">'openai'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> openai = <span class="keyword">new</span> OpenAI();</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">main</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> stream = <span class="keyword">await</span> openai.chat.completions.create(&#123;</span><br><span class="line">    model: <span class="string">'gpt-4'</span>,</span><br><span class="line">    messages: [&#123; role: <span class="string">'user'</span>, content: <span class="string">'Say this is a test'</span> &#125;],</span><br><span class="line">    stream: <span class="literal">true</span>,</span><br><span class="line">  &#125;);</span><br><span class="line">  <span class="keyword">for</span> <span class="keyword">await</span> (<span class="keyword">const</span> part of stream) &#123;</span><br><span class="line">    process.stdout.write(part.choices[<span class="number">0</span>]?.delta?.content || <span class="string">''</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main();</span><br></pre></td></tr></table></figure>

<p>If you need to cancel a stream, you can <code>break</code> from the loop<br>or call <code>stream.controller.abort()</code>.</p>
<h3 id="Request-amp-Response-types"><a href="#Request-amp-Response-types" class="headerlink" title="Request &amp; Response types"></a>Request &amp; Response types</h3><p>This library includes TypeScript definitions for all request params and response fields. You may import and use them like so:</p>
<figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> OpenAI <span class="keyword">from</span> <span class="string">'openai'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> openai = <span class="keyword">new</span> OpenAI(&#123;</span><br><span class="line">  apiKey: <span class="string">'my api key'</span>, <span class="comment">// defaults to process.env["OPENAI_API_KEY"]</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">main</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> params: OpenAI.Chat.ChatCompletionCreateParams = &#123;</span><br><span class="line">    messages: [&#123; role: <span class="string">'user'</span>, content: <span class="string">'Say this is a test'</span> &#125;],</span><br><span class="line">    model: <span class="string">'gpt-3.5-turbo'</span>,</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">const</span> completion: OpenAI.Chat.ChatCompletion = <span class="keyword">await</span> openai.chat.completions.create(params);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main();</span><br></pre></td></tr></table></figure>

<p>Documentation for each method, request param, and response field are available in docstrings and will appear on hover in most modern editors.</p>
<blockquote>
<p>[!IMPORTANT]<br>Previous versions of this SDK used a <code>Configuration</code> class. See the <a href="https://github.com/openai/openai-node/discussions/217" target="_blank" rel="noopener">v3 to v4 migration guide</a>.</p>
</blockquote>
<h2 id="File-Uploads"><a href="#File-Uploads" class="headerlink" title="File Uploads"></a>File Uploads</h2><p>Request parameters that correspond to file uploads can be passed in many different forms:</p>
<ul>
<li><code>File</code> (or an object with the same structure)</li>
<li>a <code>fetch</code> <code>Response</code> (or an object with the same structure)</li>
<li>an <code>fs.ReadStream</code></li>
<li>the return value of our <code>toFile</code> helper</li>
</ul>
<figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> fs <span class="keyword">from</span> <span class="string">'fs'</span>;</span><br><span class="line"><span class="keyword">import</span> fetch <span class="keyword">from</span> <span class="string">'node-fetch'</span>;</span><br><span class="line"><span class="keyword">import</span> OpenAI, &#123; toFile &#125; <span class="keyword">from</span> <span class="string">'openai'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> openai = <span class="keyword">new</span> OpenAI();</span><br><span class="line"></span><br><span class="line"><span class="comment">// If you have access to Node `fs` we recommend using `fs.createReadStream()`:</span></span><br><span class="line"><span class="keyword">await</span> openai.files.create(&#123; file: fs.createReadStream(<span class="string">'input.jsonl'</span>), purpose: <span class="string">'fine-tune'</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Or if you have the web `File` API you can pass a `File` instance:</span></span><br><span class="line"><span class="keyword">await</span> openai.files.create(&#123; file: <span class="keyword">new</span> File([<span class="string">'my bytes'</span>], <span class="string">'input.jsonl'</span>), purpose: <span class="string">'fine-tune'</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// You can also pass a `fetch` `Response`:</span></span><br><span class="line"><span class="keyword">await</span> openai.files.create(&#123; file: <span class="keyword">await</span> fetch(<span class="string">'https://somesite/input.jsonl'</span>), purpose: <span class="string">'fine-tune'</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Finally, if none of the above are convenient, you can use our `toFile` helper:</span></span><br><span class="line"><span class="keyword">await</span> openai.files.create(&#123;</span><br><span class="line">  file: <span class="keyword">await</span> toFile(Buffer.from(<span class="string">'my bytes'</span>), <span class="string">'input.jsonl'</span>),</span><br><span class="line">  purpose: <span class="string">'fine-tune'</span>,</span><br><span class="line">&#125;);</span><br><span class="line"><span class="keyword">await</span> openai.files.create(&#123;</span><br><span class="line">  file: <span class="keyword">await</span> toFile(<span class="keyword">new</span> <span class="built_in">Uint8Array</span>([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]), <span class="string">'input.jsonl'</span>),</span><br><span class="line">  purpose: <span class="string">'fine-tune'</span>,</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h2 id="Handling-errors"><a href="#Handling-errors" class="headerlink" title="Handling errors"></a>Handling errors</h2><p>When the library is unable to connect to the API,<br>or if the API returns a non-success status code (i.e., 4xx or 5xx response),<br>a subclass of <code>APIError</code> will be thrown:</p>
<figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">main</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> fineTune = <span class="keyword">await</span> openai.fineTunes</span><br><span class="line">    .create(&#123; training_file: <span class="string">'file-XGinujblHPwGLSztz8cPS8XY'</span> &#125;)</span><br><span class="line">    .catch(<span class="function">(<span class="params">err</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (err <span class="keyword">instanceof</span> OpenAI.APIError) &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(err.status); <span class="comment">// 400</span></span><br><span class="line">        <span class="built_in">console</span>.log(err.name); <span class="comment">// BadRequestError</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">console</span>.log(err.headers); <span class="comment">// &#123;server: 'nginx', ...&#125;</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> err;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main();</span><br></pre></td></tr></table></figure>

<p>Error codes are as followed:</p>
<table>
<thead>
<tr>
<th>Status Code</th>
<th>Error Type</th>
</tr>
</thead>
<tbody><tr>
<td>400</td>
<td><code>BadRequestError</code></td>
</tr>
<tr>
<td>401</td>
<td><code>AuthenticationError</code></td>
</tr>
<tr>
<td>403</td>
<td><code>PermissionDeniedError</code></td>
</tr>
<tr>
<td>404</td>
<td><code>NotFoundError</code></td>
</tr>
<tr>
<td>422</td>
<td><code>UnprocessableEntityError</code></td>
</tr>
<tr>
<td>429</td>
<td><code>RateLimitError</code></td>
</tr>
<tr>
<td>&gt;=500</td>
<td><code>InternalServerError</code></td>
</tr>
<tr>
<td>N/A</td>
<td><code>APIConnectionError</code></td>
</tr>
</tbody></table>
<h3 id="Azure-OpenAI"><a href="#Azure-OpenAI" class="headerlink" title="Azure OpenAI"></a>Azure OpenAI</h3><p>An example of using this library with Azure OpenAI can be found <a href="https://github.com/openai/openai-node/blob/master/examples/azure.ts" target="_blank" rel="noopener">here</a>.</p>
<p>Please note there are subtle differences in API shape &amp; behavior between the Azure OpenAI API and the OpenAI API,<br>so using this library with Azure OpenAI may result in incorrect types, which can lead to bugs.</p>
<p>See <a href="https://www.npmjs.com/package/@azure/openai" target="_blank" rel="noopener"><code>@azure/openai</code></a> for an Azure-specific SDK provided by Microsoft.</p>
<h3 id="Retries"><a href="#Retries" class="headerlink" title="Retries"></a>Retries</h3><p>Certain errors will be automatically retried 2 times by default, with a short exponential backoff.<br>Connection errors (for example, due to a network connectivity problem), 409 Conflict, 429 Rate Limit,<br>and &gt;=500 Internal errors will all be retried by default.</p>
<p>You can use the <code>maxRetries</code> option to configure or disable this:</p>
<!-- prettier-ignore -->
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Configure the default for all requests:</span></span><br><span class="line"><span class="keyword">const</span> openai = <span class="keyword">new</span> OpenAI(&#123;</span><br><span class="line">  maxRetries: <span class="number">0</span>, <span class="comment">// default is 2</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Or, configure per-request:</span></span><br><span class="line"><span class="keyword">await</span> openai.chat.completions.create(&#123; <span class="attr">messages</span>: [&#123; <span class="attr">role</span>: <span class="string">'user'</span>, <span class="attr">content</span>: <span class="string">'How can I get the name of the current day in Node.js?'</span> &#125;], <span class="attr">model</span>: <span class="string">'gpt-3.5-turbo'</span> &#125;, &#123;</span><br><span class="line">  maxRetries: <span class="number">5</span>,</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h3 id="Timeouts"><a href="#Timeouts" class="headerlink" title="Timeouts"></a>Timeouts</h3><p>Requests time out after 10 minutes by default. You can configure this with a <code>timeout</code> option:</p>
<!-- prettier-ignore -->
<figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Configure the default for all requests:</span></span><br><span class="line"><span class="keyword">const</span> openai = <span class="keyword">new</span> OpenAI(&#123;</span><br><span class="line">  timeout: <span class="number">20</span> * <span class="number">1000</span>, <span class="comment">// 20 seconds (default is 10 minutes)</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Override per-request:</span></span><br><span class="line"><span class="keyword">await</span> openai.chat.completions.create(&#123; messages: [&#123; role: <span class="string">'user'</span>, content: <span class="string">'How can I list all files in a directory using Python?'</span> &#125;], model: <span class="string">'gpt-3.5-turbo'</span> &#125;, &#123;</span><br><span class="line">  timeout: <span class="number">5</span> * <span class="number">1000</span>,</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>On timeout, an <code>APIConnectionTimeoutError</code> is thrown.</p>
<p>Note that requests which time out will be <a href="#retries">retried twice by default</a>.</p>
<h2 id="Auto-pagination"><a href="#Auto-pagination" class="headerlink" title="Auto-pagination"></a>Auto-pagination</h2><p>List methods in the OpenAI API are paginated.<br>You can use <code>for await … of</code> syntax to iterate through items across all pages:</p>
<figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">fetchAllFineTuningJobs</span>(<span class="params">params</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> allFineTuningJobs = [];</span><br><span class="line">  <span class="comment">// Automatically fetches more pages as needed.</span></span><br><span class="line">  <span class="keyword">for</span> <span class="keyword">await</span> (<span class="keyword">const</span> job of openai.fineTuning.jobs.list(&#123; limit: <span class="number">20</span> &#125;)) &#123;</span><br><span class="line">    allFineTuningJobs.push(job);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> allFineTuningJobs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Alternatively, you can make request a single page at a time:</p>
<figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> page = <span class="keyword">await</span> openai.fineTuning.jobs.list(&#123; limit: <span class="number">20</span> &#125;);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">const</span> job of page.data) &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(job);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convenience methods are provided for manually paginating:</span></span><br><span class="line"><span class="keyword">while</span> (page.hasNextPage()) &#123;</span><br><span class="line">  page = page.getNextPage();</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Advanced-Usage"><a href="#Advanced-Usage" class="headerlink" title="Advanced Usage"></a>Advanced Usage</h2><h3 id="Accessing-raw-Response-data-e-g-headers"><a href="#Accessing-raw-Response-data-e-g-headers" class="headerlink" title="Accessing raw Response data (e.g., headers)"></a>Accessing raw Response data (e.g., headers)</h3><p>The “raw” <code>Response</code> returned by <code>fetch()</code> can be accessed through the <code>.asResponse()</code> method on the <code>APIPromise</code> type that all methods return.</p>
<p>You can also use the <code>.withResponse()</code> method to get the raw <code>Response</code> along with the parsed data.</p>
<figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> openai = <span class="keyword">new</span> OpenAI();</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> response = <span class="keyword">await</span> openai.chat.completions</span><br><span class="line">  .create(&#123; messages: [&#123; role: <span class="string">'user'</span>, content: <span class="string">'Say this is a test'</span> &#125;], model: <span class="string">'gpt-3.5-turbo'</span> &#125;)</span><br><span class="line">  .asResponse();</span><br><span class="line"><span class="built_in">console</span>.log(response.headers.get(<span class="string">'X-My-Header'</span>));</span><br><span class="line"><span class="built_in">console</span>.log(response.statusText); <span class="comment">// access the underlying Response object</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> &#123; data: completions, response: raw &#125; = <span class="keyword">await</span> openai.chat.completions</span><br><span class="line">  .create(&#123; messages: [&#123; role: <span class="string">'user'</span>, content: <span class="string">'Say this is a test'</span> &#125;], model: <span class="string">'gpt-3.5-turbo'</span> &#125;)</span><br><span class="line">  .withResponse();</span><br><span class="line"><span class="built_in">console</span>.log(raw.headers.get(<span class="string">'X-My-Header'</span>));</span><br><span class="line"><span class="built_in">console</span>.log(completions.choices);</span><br></pre></td></tr></table></figure>

<h2 id="Configuring-an-HTTP-S-Agent-e-g-for-proxies"><a href="#Configuring-an-HTTP-S-Agent-e-g-for-proxies" class="headerlink" title="Configuring an HTTP(S) Agent (e.g., for proxies)"></a>Configuring an HTTP(S) Agent (e.g., for proxies)</h2><p>By default, this library uses a stable agent for all http/https requests to reuse TCP connections, eliminating many TCP &amp; TLS handshakes and shaving around 100ms off most requests.</p>
<p>If you would like to disable or customize this behavior, for example to use the API behind a proxy, you can pass an <code>httpAgent</code> which is used for all requests (be they http or https), for example:</p>
<!-- prettier-ignore -->
<figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> http <span class="keyword">from</span> <span class="string">'http'</span>;</span><br><span class="line"><span class="keyword">import</span> HttpsProxyAgent <span class="keyword">from</span> <span class="string">'https-proxy-agent'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Configure the default for all requests:</span></span><br><span class="line"><span class="keyword">const</span> openai = <span class="keyword">new</span> OpenAI(&#123;</span><br><span class="line">  httpAgent: <span class="keyword">new</span> HttpsProxyAgent(process.env.PROXY_URL),</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Override per-request:</span></span><br><span class="line"><span class="keyword">await</span> openai.models.list(&#123;</span><br><span class="line">  baseURL: <span class="string">'http://localhost:8080/test-api'</span>,</span><br><span class="line">  httpAgent: <span class="keyword">new</span> http.Agent(&#123; keepAlive: <span class="literal">false</span> &#125;),</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<h2 id="Semantic-Versioning"><a href="#Semantic-Versioning" class="headerlink" title="Semantic Versioning"></a>Semantic Versioning</h2><p>This package generally attempts to follow <a href="https://semver.org/spec/v2.0.0.html" target="_blank" rel="noopener">SemVer</a> conventions, though certain backwards-incompatible changes may be released as minor versions:</p>
<ol>
<li>Changes that only affect static types, without breaking runtime behavior.</li>
<li>Changes to library internals which are technically public but not intended or documented for external use. <em>(Please open a GitHub issue to let us know if you are relying on such internals)</em>.</li>
<li>Changes that we do not expect to impact the vast majority of users in practice.</li>
</ol>
<p>We take backwards-compatibility seriously and work hard to ensure you can rely on a smooth upgrade experience.</p>
<p>We are keen for your feedback; please open an <a href="https://www.github.com/openai/openai-node/issues" target="_blank" rel="noopener">issue</a> with questions, bugs, or suggestions.</p>
<h2 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h2><p>TypeScript &gt;= 4.5 is supported.</p>
<p>The following runtimes are supported:</p>
<ul>
<li>Node.js 16 LTS or later (<a href="https://endoflife.date/nodejs" target="_blank" rel="noopener">non-EOL</a>) versions.</li>
<li>Deno v1.28.0 or higher, using <code>import OpenAI from &quot;npm:openai&quot;</code>.<br>Deno Deploy is not yet supported.</li>
<li>Cloudflare Workers.</li>
<li>Vercel Edge Runtime.</li>
</ul>
<p>If you are interested in other runtime environments, please open or upvote an issue on GitHub.</p>

            


            <h3>转载申请</h3>
            <p>本作品采用<a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">知识共享署名 4.0 国际许可协议</a>进行许可，转载时请注明原文链接，文章内图片请保留全部内容。</p>
        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    <a
                        class="post-action-btn btn btn--disabled"
                        aria-hidden="true"
                    >
                        
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/post/2023/0906/index.html"
                    data-tooltip="2023/0906/index"
                    aria-label="下一篇: 2023/0906/index"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://connect.qq.com/widget/shareqq/index.html?url=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html&amp;title=2023/0908/推荐一个Node OpenAi api库"
                    title="分享到 QQ"
                    aria-label="分享到 QQ"
                >
                    <i class="fab fa-qq" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#gitalk"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Nach oben">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="gitalk"></div>

            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2023 煦涵. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    <a
                        class="post-action-btn btn btn--disabled"
                        aria-hidden="true"
                    >
                        
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/post/2023/0906/index.html"
                    data-tooltip="2023/0906/index"
                    aria-label="下一篇: 2023/0906/index"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://connect.qq.com/widget/shareqq/index.html?url=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html&amp;title=2023/0908/推荐一个Node OpenAi api库"
                    title="分享到 QQ"
                    aria-label="分享到 QQ"
                >
                    <i class="fab fa-qq" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#gitalk"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Nach oben">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="5">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html"
                        aria-label="分享到 Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>分享到 Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html"
                        aria-label="分享到 Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>分享到 Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://service.weibo.com/share/share.php?&amp;title=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html"
                        aria-label="分享到 Weibo"
                    >
                        <i class="fab fa-weibo" aria-hidden="true"></i><span>分享到 Weibo</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://connect.qq.com/widget/shareqq/index.html?url=https://zuojj.com/post/2023/0908/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AANode%20OpenAi%20api%E5%BA%93.html&amp;title=2023/0908/推荐一个Node OpenAi api库"
                        aria-label="分享到 QQ"
                    >
                        <i class="fab fa-qq" aria-hidden="true"></i><span>分享到 QQ</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/android-icon-192x192.png" alt="作者的图片" onerror="this.style.display='none'"/>
        
            <h4 id="about-card-name">煦涵</h4>
        
            <div id="about-card-bio"><p>因为热爱，所以坚持。</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Developer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Beijing
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover01.jpeg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-ah8fu2oihbm9frbz1pxa0jkqer1zb0klgkgmuaenrh4k2naxqcwf4av0zlc2.min.js"></script>

<!--SCRIPTS END-->


    
        
<script src="/assets/js/gitalk.js"></script>

        <script type="text/javascript">
          (function() {
            new Gitalk({
              clientID: 'c7c1ad823b46b771570d',
              clientSecret: '46d251bb9ed9d97efcf23a00db098bf7f7400a31',
              repo: 'zuojj.github.io',
              owner: 'zuojj',
              admin: ['zuojj'],
              id: 'post/2023/0908/推荐一个Node OpenAi api库.html',
              ...{"language":"en","perPage":10,"distractionFreeMode":false,"enableHotKey":true,"pagerDirection":"first"}
            }).render('gitalk')
          })()
        </script>
    




    </body>
</html>
